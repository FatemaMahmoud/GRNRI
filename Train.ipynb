{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import pickle\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from utils import *\n",
    "from modules import *\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifty the arguments and run all the cells in order to start training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of running MHSC-GM dataset while using Non-specific ChIP-Seq network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--compute-acc'], dest='compute_acc', nargs=0, const=True, default=True, type=None, choices=None, help='whether to compute accuracy for each batch..', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                    help='Disables CUDA training.')\n",
    "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=180,\n",
    "                    help='Number of epochs to train.')\n",
    "parser.add_argument('--batch-size', type=int, default=11,\n",
    "                    help='Number of samples per batch.')\n",
    "parser.add_argument('--lr', type=float, default=0.0005,\n",
    "                    help='Initial learning rate.')\n",
    "parser.add_argument('--encoder-hidden', type=int, default=64,\n",
    "                    help='Number of hidden units.')\n",
    "parser.add_argument('--decoder-hidden', type=int, default=64,\n",
    "                    help='Number of hidden units.')\n",
    "parser.add_argument('--temp', type=float, default=0.5,\n",
    "                    help='Temperature for Gumbel softmax.')\n",
    "parser.add_argument('--num-atoms', type=int, default=301,\n",
    "                    help='Number of genes.')\n",
    "parser.add_argument('--num-tfs', type=int, default=82,\n",
    "                    help='Number of transcription factors.')\n",
    "parser.add_argument('--density', type=int, default=0.03,\n",
    "                    help='Density of edges in the network.')\n",
    "parser.add_argument('--encoder', type=str, default='mlp',\n",
    "                    help='Type of path encoder model (mlp).')\n",
    "parser.add_argument('--decoder', type=str, default='mlp',\n",
    "                    help='Type of decoder model (mlp or sim).')\n",
    "parser.add_argument('--no-factor', action='store_true', default=False,\n",
    "                    help='Disables factor graph model.')\n",
    "parser.add_argument('--suffix', type=str, default='_rna',\n",
    "                    help='Suffix for training data (e.g. \"_charged\".')\n",
    "parser.add_argument('--encoder-dropout', type=float, default=0.0,\n",
    "                    help='Dropout rate (1 - keep probability).')\n",
    "parser.add_argument('--decoder-dropout', type=float, default=0.0,\n",
    "                    help='Dropout rate (1 - keep probability).')\n",
    "parser.add_argument('--save-folder', type=str, default=os.path.dirname(os.path.abspath('logs')),\n",
    "                    help='Where to save the trained model, leave empty to not save anything.')\n",
    "parser.add_argument('--load-folder', type=str, default='',\n",
    "                    help='Where to load the trained model if finetunning. ' +\n",
    "                         'Leave empty to train from scratch')\n",
    "parser.add_argument('--edge-types', type=int, default=2,\n",
    "                    help='The number of edge types to infer.')\n",
    "parser.add_argument('--dims', type=int, default=1,\n",
    "                    help='The number of input dimensions (position + velocity).')\n",
    "parser.add_argument('--timesteps', type=int, default=1,\n",
    "                    help='The number of time steps per sample.')\n",
    "parser.add_argument('--prediction-steps', type=int, default=1, metavar='N',\n",
    "                    help='Num steps to predict before re-using teacher forcing.')\n",
    "parser.add_argument('--lr-decay', type=int, default=80,\n",
    "                    help='After how epochs to decay LR by a factor of gamma.')\n",
    "parser.add_argument('--gamma', type=float, default=0.4,\n",
    "                    help='LR decay factor.')\n",
    "parser.add_argument('--skip-first', action='store_true', default=False,\n",
    "                    help='Skip first edge type in decoder, i.e. it represents no-edge.')\n",
    "parser.add_argument('--var', type=float, default=5e-5,\n",
    "                    help='Output variance.')\n",
    "parser.add_argument('--hard', action='store_true', default=True,\n",
    "                    help='Uses discrete samples in training forward pass.')\n",
    "parser.add_argument('--prior', action='store_true', default=True,\n",
    "                    help='Whether to use sparsity prior.')\n",
    "parser.add_argument('--dynamic-graph', action='store_true', default=False,\n",
    "                    help='Whether test with dynamically re-computed graph.')\n",
    "parser.add_argument('--compute-acc', action='store_true', default=True,\n",
    "                    help='whether to compute accuracy for each batch..')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(no_cuda=False, seed=42, epochs=180, batch_size=11, lr=0.0005, encoder_hidden=64, decoder_hidden=64, temp=0.5, num_atoms=301, num_tfs=82, density=0.03, encoder='mlp', decoder='mlp', no_factor=False, suffix='_rna', encoder_dropout=0.0, decoder_dropout=0.0, save_folder='C:\\\\Users\\\\CSE-Admin\\\\Documents\\\\Gene Regulatory Network Project\\\\NRI-master\\\\NRI-master', load_folder='', edge_types=2, dims=1, timesteps=1, prediction_steps=1, lr_decay=80, gamma=0.4, skip_first=False, var=5e-05, hard=True, prior=True, dynamic_graph=False, compute_acc=True, cuda=True, factor=True)\n"
     ]
    }
   ],
   "source": [
    "args, unknown = parser.parse_known_args()\n",
    "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "args.factor = not args.no_factor\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "if args.cuda:\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "if args.dynamic_graph:\n",
    "    print(\"Testing with dynamically re-computed graph.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and meta-data. Always saves in a new sub-folder.\n",
    "if args.save_folder:\n",
    "    exp_counter = 0\n",
    "    now = datetime.datetime.now()\n",
    "    timestamp = now.isoformat()\n",
    "    save_folder = 'result'.format(args.save_folder, timestamp)\n",
    "    os.makedirs(save_folder)\n",
    "    meta_file = os.path.join(save_folder, 'metadata.pkl')\n",
    "    encoder_file = os.path.join(save_folder, 'encoder.pt')\n",
    "    decoder_file = os.path.join(save_folder, 'decoder.pt')\n",
    "\n",
    "    log_file = os.path.join(save_folder, 'log.txt')\n",
    "    log = open(log_file, 'w')\n",
    "\n",
    "    pickle.dump({'args': args}, open(meta_file, \"wb\"))\n",
    "else:\n",
    "    print(\"WARNING: No save_folder provided!\" +\n",
    "          \"Testing (within this script) will throw an error.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing mask \n",
    "ex_tfs = np.zeros([args.num_atoms, args.num_atoms])\n",
    "for i in range(args.num_tfs,args.num_atoms):\n",
    "    for j in range(args.num_atoms):\n",
    "        ex_tfs[i,j] = 1\n",
    "        \n",
    "off_diag = np.ones([args.num_atoms, args.num_atoms]) - np.eye(args.num_atoms) \n",
    "off_diag = off_diag - ex_tfs\n",
    "\n",
    "off_diag[off_diag == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rel_rec = np.array(encode_onehot(np.where(off_diag)[1]), dtype=np.int16)\n",
    "rel_send = np.array(encode_onehot(np.where(off_diag)[0]), dtype=np.int16)\n",
    "rel_rec = torch.FloatTensor(rel_rec)\n",
    "rel_send = torch.FloatTensor(rel_send)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = rel_rec.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MLP encoder.\n"
     ]
    }
   ],
   "source": [
    "encoder = MLPEncoder(args.timesteps * args.dims, args.encoder_hidden,\n",
    "                         args.edge_types,\n",
    "                         args.encoder_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using learned interaction net decoder.\n"
     ]
    }
   ],
   "source": [
    "if args.decoder == 'mlp':\n",
    "    decoder = MLPDecoder(n_in_node=args.dims,\n",
    "                         edge_types=args.edge_types,\n",
    "                         msg_hid=args.decoder_hidden,\n",
    "                         msg_out=args.decoder_hidden,\n",
    "                         n_hid=args.decoder_hidden,\n",
    "                         do_prob=args.decoder_dropout,\n",
    "                         skip_first=args.skip_first)\n",
    "\n",
    "elif args.decoder == 'sim':\n",
    "    decoder = SimulationDecoder(loc_max, loc_min, args.suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.load_folder:\n",
    "    encoder_file = os.path.join(args.load_folder, 'encoder.pt')\n",
    "    encoder.load_state_dict(torch.load(encoder_file))\n",
    "    decoder_file = os.path.join(args.load_folder, 'decoder.pt')\n",
    "    decoder.load_state_dict(torch.load(decoder_file))\n",
    "\n",
    "    args.save_folder = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()),\n",
    "                       lr=args.lr)\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=args.lr_decay,\n",
    "                                gamma=args.gamma, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using prior\n"
     ]
    }
   ],
   "source": [
    "if args.prior:\n",
    "    prior = np.array([1-args.density, args.density])  # TODO: hard coded for now\n",
    "    print(\"Using prior\")\n",
    "    log_prior = torch.FloatTensor(np.log(prior))\n",
    "    log_prior = torch.unsqueeze(log_prior, 0)\n",
    "    log_prior = torch.unsqueeze(log_prior, 0)\n",
    "    log_prior = Variable(log_prior)\n",
    "\n",
    "    if args.cuda:\n",
    "        log_prior = log_prior.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.cuda:\n",
    "    encoder.cuda()\n",
    "    decoder.cuda()\n",
    "    rel_rec = rel_rec.cuda()\n",
    "    rel_send = rel_send.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_loader, loc_max, loc_min = load_data(args.num_tfs, args.batch_size, args.suffix, args.compute_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_edges = np.load('data/true_edges.npy', allow_pickle=True)\n",
    "rel_send_idx = np.array((np.where(off_diag)[0]), dtype=np.int16) \n",
    "rel_rec_idx = np.array((np.where(off_diag)[1]), dtype=np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, best_eprec):\n",
    "    t = time.time()\n",
    "    nll_train = []\n",
    "    kl_train = []\n",
    "    mse_train = []\n",
    "    if(args.compute_acc):\n",
    "        acc_train = []\n",
    "    all_edges_preds = np.zeros(sh)\n",
    "\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    \n",
    "    \n",
    "    for batch_idx, (data, relations) in enumerate(train_loader):\n",
    "        if args.cuda:\n",
    "            data, relations = data.cuda(), relations.cuda()\n",
    "        data, relations = Variable(data), Variable(relations)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = encoder(data, rel_rec, rel_send, args.num_tfs)\n",
    "    \n",
    "        edges = gumbel_softmax(logits, tau=args.temp, hard=True)\n",
    "        prob = my_softmax(logits, -1)\n",
    "\n",
    "        output = torch.squeeze(decoder(data, edges, rel_rec, rel_send, args.num_tfs, 0))\n",
    "\n",
    "        target = torch.squeeze(data)\n",
    "\n",
    "        loss_nll = nll_gaussian(output, target, args.var)\n",
    "\n",
    "        if args.prior:\n",
    "            loss_kl = kl_categorical(prob, log_prior, args.num_atoms)\n",
    "        else:\n",
    "            loss_kl = kl_categorical_uniform(prob, args.num_atoms,\n",
    "                                             args.edge_types)\n",
    "        \n",
    "        if(args.compute_acc):\n",
    "            acc = edge_accuracy(logits, relations)\n",
    "            acc_train.append(acc)\n",
    "        mse_train.append(F.mse_loss(output, target).item())\n",
    "        nll_train.append(loss_nll.item())\n",
    "        kl_train.append(loss_kl.item())\n",
    "        all_edges_preds = edge_precision_util(logits, all_edges_preds)\n",
    "        _, preds = logits.max(-1)\n",
    "        \n",
    "        sparse_loss = np.mean(np.absolute(list(encoder.parameters())[0].cpu().data.numpy())) + np.mean(np.absolute(list(decoder.parameters())[0].cpu().data.numpy()))\n",
    "        \n",
    "\n",
    "        loss = loss_nll + loss_kl #+ 100 * sparse_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    scheduler.step()\n",
    "    eprecR_train_whole = calc_eprec_net(all_edges_preds)\n",
    "    \n",
    "    \n",
    "    if(args.compute_acc):\n",
    "        acc_eval = []\n",
    "    all_edges_preds = np.zeros(sh)\n",
    "\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    for batch_idx, (data, relations) in enumerate(train_loader):\n",
    "        if args.cuda:\n",
    "            data, relations = data.cuda(), relations.cuda()\n",
    "        data, relations = Variable(data), Variable(\n",
    "            relations)\n",
    "\n",
    "        logits = encoder(data, rel_rec, rel_send, args.num_tfs)\n",
    "        edges = gumbel_softmax(logits, tau=args.temp, hard=True)\n",
    "        prob = my_softmax(logits, -1)\n",
    "\n",
    "        output = decoder(data, edges, rel_rec, rel_send, args.num_tfs, 0)\n",
    "\n",
    "        target = data\n",
    "        \n",
    "        if(args.compute_acc):\n",
    "            acc = edge_accuracy(logits, relations)\n",
    "            acc_eval.append(acc)\n",
    "        all_edges_preds = edge_precision_util(logits, all_edges_preds)                     \n",
    "\n",
    "    eprecR_eval_whole = calc_eprec_net(all_edges_preds)\n",
    "    \n",
    "    if(args.compute_acc):\n",
    "        print('Epoch: {:04d}'.format(epoch),\n",
    "            'nll_train: {:.10f}'.format(np.mean(nll_train)),\n",
    "              'kl_train: {:.10f}'.format(np.mean(kl_train)),\n",
    "              'mse_train: {:.10f}'.format(np.mean(mse_train)),\n",
    "              'acc_train: {:.10f}'.format(np.mean(acc_train)),\n",
    "              'eprecR_train: {:.10f}'.format((eprecR_train_whole)),\n",
    "              'acc_eval: {:.10f}'.format(np.mean(acc_eval)),\n",
    "              'eprecR_eval: {:.10f}'.format((eprecR_eval_whole)),\n",
    "              'time: {:.4f}s'.format(time.time() - t),\n",
    "              \"-----------------------------------------------\",\n",
    "              \"-----------------------------------------------\")\n",
    "    else: \n",
    "        print('Epoch: {:04d}'.format(epoch),\n",
    "            'nll_train: {:.10f}'.format(np.mean(nll_train)),\n",
    "              'kl_train: {:.10f}'.format(np.mean(kl_train)),\n",
    "              'mse_train: {:.10f}'.format(np.mean(mse_train)),\n",
    "              'eprecR_train: {:.10f}'.format((eprecR_train_whole)),\n",
    "              'eprecR_eval: {:.10f}'.format((eprecR_eval_whole)),\n",
    "              'time: {:.4f}s'.format(time.time() - t),\n",
    "              \"-----------------------------------------------\",\n",
    "              \"-----------------------------------------------\")\n",
    "    \n",
    "    if eprecR_eval_whole > eprecR_train_whole: \n",
    "        max_eprec = eprecR_eval_whole\n",
    "    else:\n",
    "        max_eprec = eprecR_train_whole\n",
    "\n",
    "    if args.save_folder and max_eprec > best_eprec:\n",
    "        torch.save(encoder.state_dict(), encoder_file)\n",
    "        torch.save(decoder.state_dict(), decoder_file)\n",
    "        print('Best model so far, saving...')\n",
    "        print('Epoch: {:04d}'.format(epoch))\n",
    "        log.flush()\n",
    "        \n",
    "    return max_eprec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_precision_util(preds,  all_edges_preds):\n",
    "    \n",
    "    _, preds = preds.max(-1)\n",
    "    for i in range(preds.shape[0]):\n",
    "        all_edges_preds = np.add(all_edges_preds, preds[i].cpu())\n",
    "        all_edges_preds[all_edges_preds > 1] = 1\n",
    "                \n",
    "    return all_edges_preds\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_eprec_net(preds):\n",
    "\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    for i in range(preds.shape[0]):\n",
    "        if(preds[i] == 1):\n",
    "            if(true_edges[rel_send_idx[i], rel_rec_idx[i]] == 1):\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "\n",
    "    \n",
    "    if(tp + fp == 0):\n",
    "        prec = 0\n",
    "    else:\n",
    "        prec = tp / (tp + fp)\n",
    "    return 1. * prec/args.density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0000 nll_train: 77.3127313985 kl_train: -5.0855905221 mse_train: 0.0077312733 acc_train: 0.4725694666 eprecR_train: 1.0067750678 acc_eval: 0.5048753012 eprecR_eval: 1.0067750678 time: 8.5625s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0000\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0001 nll_train: 1.4214158559 kl_train: -9.0757377766 mse_train: 0.0001421416 acc_train: 0.4660859777 eprecR_train: 1.0067750678 acc_eval: 0.4459094711 eprecR_eval: 1.0067750678 time: 7.4092s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0002 nll_train: 0.8705251290 kl_train: -9.2223109963 mse_train: 0.0000870525 acc_train: 0.4925435019 eprecR_train: 1.0067750678 acc_eval: 0.4789900460 eprecR_eval: 1.0067750678 time: 7.4122s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0003 nll_train: 0.5701132214 kl_train: -9.2636998024 mse_train: 0.0000570113 acc_train: 0.4996884635 eprecR_train: 1.0067750678 acc_eval: 0.5134194145 eprecR_eval: 1.0067750678 time: 7.3713s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0004 nll_train: 0.4120542698 kl_train: -9.2820967922 mse_train: 0.0000412054 acc_train: 0.5081948360 eprecR_train: 1.0067750678 acc_eval: 0.4937028673 eprecR_eval: 1.0067750678 time: 7.4092s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0005 nll_train: 0.3257443583 kl_train: -9.2922835173 mse_train: 0.0000325744 acc_train: 0.4960299472 eprecR_train: 1.0067750678 acc_eval: 0.4927138797 eprecR_eval: 1.0067750678 time: 7.4092s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0006 nll_train: 0.2626520301 kl_train: -9.2988062788 mse_train: 0.0000262652 acc_train: 0.4909835938 eprecR_train: 1.0067750678 acc_eval: 0.4275446222 eprecR_eval: 1.0067750678 time: 7.4211s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0007 nll_train: 0.2470743354 kl_train: -9.3034504726 mse_train: 0.0000247074 acc_train: 0.4787420729 eprecR_train: 1.0067750678 acc_eval: 0.3389360077 eprecR_eval: 1.0067750678 time: 7.3842s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0008 nll_train: 0.2076450481 kl_train: -9.3067561020 mse_train: 0.0000207645 acc_train: 0.4730486233 eprecR_train: 1.0067750678 acc_eval: 0.4066589158 eprecR_eval: 1.0067750678 time: 7.3813s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0009 nll_train: 0.1668681825 kl_train: -9.3094876372 mse_train: 0.0000166868 acc_train: 0.4724233046 eprecR_train: 1.0067750678 acc_eval: 0.3281678980 eprecR_eval: 1.0067750678 time: 7.3444s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0010 nll_train: 0.1518647202 kl_train: -9.3116814295 mse_train: 0.0000151865 acc_train: 0.4906120626 eprecR_train: 1.0067750678 acc_eval: 0.4130120233 eprecR_eval: 1.0067750678 time: 7.4850s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0011 nll_train: 0.1381949619 kl_train: -9.3134669021 mse_train: 0.0000138195 acc_train: 0.5658395204 eprecR_train: 1.0067750678 acc_eval: 0.5107373342 eprecR_eval: 1.0067750678 time: 7.4471s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0012 nll_train: 0.1549970916 kl_train: -9.3148826670 mse_train: 0.0000154997 acc_train: 0.6184334360 eprecR_train: 1.0067750678 acc_eval: 0.4617201119 eprecR_eval: 1.0067750678 time: 7.3833s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0013 nll_train: 0.1200210415 kl_train: -9.3162527025 mse_train: 0.0000120021 acc_train: 0.6344390203 eprecR_train: 1.0067750678 acc_eval: 0.5846186243 eprecR_eval: 1.0067750678 time: 7.4820s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0014 nll_train: 0.1081482658 kl_train: -9.3173616904 mse_train: 0.0000108148 acc_train: 0.6871118695 eprecR_train: 1.0067750678 acc_eval: 0.5472711406 eprecR_eval: 1.0067750678 time: 7.6695s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0015 nll_train: 0.1359768698 kl_train: -9.3183338142 mse_train: 0.0000135977 acc_train: 0.6808850525 eprecR_train: 1.0067750678 acc_eval: 0.5804351809 eprecR_eval: 1.0067750678 time: 7.5221s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0016 nll_train: 0.1247073794 kl_train: -9.3191871996 mse_train: 0.0000124707 acc_train: 0.7550064177 eprecR_train: 1.0067750678 acc_eval: 0.7382376003 eprecR_eval: 1.0067750678 time: 7.4870s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0017 nll_train: 0.1371592776 kl_train: -9.3199077359 mse_train: 0.0000137159 acc_train: 0.7879855161 eprecR_train: 1.0067750678 acc_eval: 0.7922711913 eprecR_eval: 1.0067750678 time: 7.5030s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0018 nll_train: 0.1550610174 kl_train: -9.3204653293 mse_train: 0.0000155061 acc_train: 0.7891699287 eprecR_train: 1.0067750678 acc_eval: 0.7563233763 eprecR_eval: 1.0067750678 time: 7.5737s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0019 nll_train: 0.2025119874 kl_train: -9.3212660801 mse_train: 0.0000202512 acc_train: 0.7737093661 eprecR_train: 1.0067750678 acc_eval: 0.7473808191 eprecR_eval: 1.0067750678 time: 7.5219s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0020 nll_train: 0.1476145820 kl_train: -9.3217835132 mse_train: 0.0000147615 acc_train: 0.7989571769 eprecR_train: 1.0067750678 acc_eval: 0.8099507318 eprecR_eval: 1.0067750678 time: 7.4850s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0021 nll_train: 0.1326482141 kl_train: -9.3223158636 mse_train: 0.0000132648 acc_train: 0.8263188596 eprecR_train: 1.0067750678 acc_eval: 0.8443532180 eprecR_eval: 1.0067750678 time: 7.4979s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0022 nll_train: 0.2049284605 kl_train: -9.3227316892 mse_train: 0.0000204928 acc_train: 0.8627851840 eprecR_train: 1.0067750678 acc_eval: 0.8950832373 eprecR_eval: 1.0067750678 time: 7.6625s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0023 nll_train: 0.4327989774 kl_train: -9.3231236434 mse_train: 0.0000432799 acc_train: 0.8851750974 eprecR_train: 1.0067750678 acc_eval: 0.9075640729 eprecR_eval: 1.0067750678 time: 7.4730s ----------------------------------------------- -----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0024 nll_train: 0.2742622421 kl_train: -9.3233741772 mse_train: 0.0000274262 acc_train: 0.8508886973 eprecR_train: 1.0067750678 acc_eval: 0.8152313662 eprecR_eval: 1.0067750678 time: 7.5119s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0025 nll_train: 0.3545241870 kl_train: -9.3234846504 mse_train: 0.0000354524 acc_train: 0.8270611363 eprecR_train: 1.0067750678 acc_eval: 0.8227374112 eprecR_eval: 1.0067750678 time: 7.4690s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0026 nll_train: 0.1795066325 kl_train: -9.3245392670 mse_train: 0.0000179507 acc_train: 0.8604381312 eprecR_train: 1.0067750678 acc_eval: 0.8734891067 eprecR_eval: 1.0067750678 time: 7.5478s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0027 nll_train: 0.3677346372 kl_train: -9.3245110924 mse_train: 0.0000367735 acc_train: 0.8522561761 eprecR_train: 1.0067750678 acc_eval: 0.8625311988 eprecR_eval: 1.0067750678 time: 7.5349s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0028 nll_train: 0.3478768709 kl_train: -9.3241772004 mse_train: 0.0000347877 acc_train: 0.8766071992 eprecR_train: 1.0067750678 acc_eval: 0.8488976587 eprecR_eval: 1.0067750678 time: 7.4670s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0029 nll_train: 0.1792439586 kl_train: -9.3254158880 mse_train: 0.0000179244 acc_train: 0.8851147579 eprecR_train: 1.0067750678 acc_eval: 0.9388708372 eprecR_eval: 1.0068978602 time: 7.4371s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0029\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0030 nll_train: 0.1270527591 kl_train: -9.3258050989 mse_train: 0.0000127053 acc_train: 0.9022455003 eprecR_train: 1.0067750678 acc_eval: 0.9645135283 eprecR_eval: 1.0112573936 time: 7.4860s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0030\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0031 nll_train: 1.1359992352 kl_train: -9.3223625171 mse_train: 0.0001135999 acc_train: 0.8994239849 eprecR_train: 1.0067750678 acc_eval: 0.9657434781 eprecR_eval: 1.0120409720 time: 7.6196s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0031\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0032 nll_train: 0.1198515671 kl_train: -9.3263261819 mse_train: 0.0000119852 acc_train: 0.9303404871 eprecR_train: 1.0067750678 acc_eval: 0.9794034240 eprecR_eval: 1.0212553969 time: 7.4770s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0032\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0033 nll_train: 0.0811333435 kl_train: -9.3267067862 mse_train: 0.0000081133 acc_train: 0.9508510529 eprecR_train: 1.0067750678 acc_eval: 0.9849751860 eprecR_eval: 1.0418467923 time: 7.4491s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0033\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0034 nll_train: 0.1380692174 kl_train: -9.3268765226 mse_train: 0.0000138069 acc_train: 0.9638131795 eprecR_train: 1.0067750678 acc_eval: 0.9882197464 eprecR_eval: 1.1175638085 time: 7.5618s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0034\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0035 nll_train: 0.7090013368 kl_train: -9.3252230868 mse_train: 0.0000709001 acc_train: 0.9637814814 eprecR_train: 1.0067750678 acc_eval: 0.9888968933 eprecR_eval: 1.1788338531 time: 7.4511s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0035\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0036 nll_train: 0.0666904221 kl_train: -9.3270123152 mse_train: 0.0000066690 acc_train: 0.9763711490 eprecR_train: 1.0071844923 acc_eval: 0.9911149536 eprecR_eval: 1.5896397226 time: 7.4152s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0036\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0037 nll_train: 0.1651037934 kl_train: -9.3273949447 mse_train: 0.0000165104 acc_train: 0.9795472389 eprecR_train: 1.0132416916 acc_eval: 0.9910484702 eprecR_eval: 1.6800535475 time: 7.4371s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0037\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0038 nll_train: 0.3805402006 kl_train: -9.3268443920 mse_train: 0.0000380540 acc_train: 0.9826302420 eprecR_train: 1.0321822683 acc_eval: 0.9914178977 eprecR_eval: 1.4531634250 time: 7.4271s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0039 nll_train: 0.3363705222 kl_train: -9.3269761403 mse_train: 0.0000336371 acc_train: 0.9799987783 eprecR_train: 1.0159095265 acc_eval: 0.9910739484 eprecR_eval: 1.6867205099 time: 7.4381s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0039\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0040 nll_train: 0.0838461995 kl_train: -9.3281241111 mse_train: 0.0000083846 acc_train: 0.9774192340 eprecR_train: 1.0095245859 acc_eval: 0.9910387423 eprecR_eval: 1.8849019976 time: 7.5927s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0040\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0041 nll_train: 0.3261020523 kl_train: -9.3277452316 mse_train: 0.0000326102 acc_train: 0.9745391940 eprecR_train: 1.0076762416 acc_eval: 0.9888418309 eprecR_eval: 1.0665303689 time: 7.4750s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0042 nll_train: 0.2080645569 kl_train: -9.3282929526 mse_train: 0.0000208065 acc_train: 0.9735387651 eprecR_train: 1.0073483554 acc_eval: 0.9910170104 eprecR_eval: 2.1071048228 time: 7.5130s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0042\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0043 nll_train: 0.3896611462 kl_train: -9.3280431547 mse_train: 0.0000389661 acc_train: 0.9756485410 eprecR_train: 1.0106368508 acc_eval: 0.9906897186 eprecR_eval: 1.3990672885 time: 7.5151s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0044 nll_train: 0.0968541517 kl_train: -9.3287398550 mse_train: 0.0000096854 acc_train: 0.9802543502 eprecR_train: 1.0146176040 acc_eval: 0.9910831085 eprecR_eval: 1.6992648079 time: 7.4680s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0045 nll_train: 0.2457087163 kl_train: -9.3277836494 mse_train: 0.0000245709 acc_train: 0.9774299048 eprecR_train: 1.0118755788 acc_eval: 0.9905151535 eprecR_eval: 1.2837209302 time: 7.4790s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0046 nll_train: 0.2834102039 kl_train: -9.3287161662 mse_train: 0.0000283410 acc_train: 0.9757889900 eprecR_train: 1.0085316325 acc_eval: 0.9905001992 eprecR_eval: 1.3321027534 time: 7.4600s ----------------------------------------------- -----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0047 nll_train: 0.1919743867 kl_train: -9.3272366641 mse_train: 0.0000191974 acc_train: 0.9750620782 eprecR_train: 1.0154851231 acc_eval: 0.9907230287 eprecR_eval: 1.4724877293 time: 7.4596s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0048 nll_train: 0.0631177235 kl_train: -9.3294410764 mse_train: 0.0000063118 acc_train: 0.9713662572 eprecR_train: 1.0066886456 acc_eval: 0.9898284562 eprecR_eval: 1.2554633842 time: 7.5149s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0049 nll_train: 0.0639754635 kl_train: -9.3294655129 mse_train: 0.0000063975 acc_train: 0.9693828377 eprecR_train: 1.0077582465 acc_eval: 0.9901424615 eprecR_eval: 1.3048635824 time: 7.5987s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0050 nll_train: 1.5898822101 kl_train: -9.3230748824 mse_train: 0.0001589882 acc_train: 0.9220030324 eprecR_train: 1.0068978602 acc_eval: 0.9831745894 eprecR_eval: 1.0058590931 time: 7.5688s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0051 nll_train: 0.0626290033 kl_train: -9.3296519739 mse_train: 0.0000062629 acc_train: 0.9753424286 eprecR_train: 1.0126202742 acc_eval: 0.9904474688 eprecR_eval: 1.3436355738 time: 7.4870s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0052 nll_train: 0.0538368168 kl_train: -9.3298890738 mse_train: 0.0000053837 acc_train: 0.9746870745 eprecR_train: 1.0097298768 acc_eval: 0.9911589193 eprecR_eval: 1.8304112912 time: 11.6279s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0053 nll_train: 0.0636405864 kl_train: -9.3298656617 mse_train: 0.0000063641 acc_train: 0.9830675520 eprecR_train: 1.0272625070 acc_eval: 0.9913695116 eprecR_eval: 1.8105263158 time: 14.2060s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0054 nll_train: 0.0547686784 kl_train: -9.3300834114 mse_train: 0.0000054769 acc_train: 0.9880084140 eprecR_train: 1.1413107424 acc_eval: 0.9915037001 eprecR_eval: 1.5652557319 time: 14.2130s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0055 nll_train: 0.0650773274 kl_train: -9.3302274751 mse_train: 0.0000065077 acc_train: 0.9898559519 eprecR_train: 1.1806012728 acc_eval: 0.9914957515 eprecR_eval: 1.5381234893 time: 14.3456s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0056 nll_train: 0.0603213795 kl_train: -9.3303296478 mse_train: 0.0000060321 acc_train: 0.9905368449 eprecR_train: 1.1952078929 acc_eval: 0.9915290058 eprecR_eval: 1.5365551425 time: 14.1771s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0057 nll_train: 0.0414450213 kl_train: -9.3303802043 mse_train: 0.0000041445 acc_train: 0.9906346310 eprecR_train: 1.2334644262 acc_eval: 0.9915760333 eprecR_eval: 1.3926733273 time: 14.2628s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0058 nll_train: 0.0682781489 kl_train: -9.3304666825 mse_train: 0.0000068278 acc_train: 0.9910563580 eprecR_train: 1.2393219139 acc_eval: 0.9915951090 eprecR_eval: 1.3831258645 time: 14.2092s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0059 nll_train: 1.3527198501 kl_train: -9.3269334722 mse_train: 0.0001352720 acc_train: 0.9807533683 eprecR_train: 1.0482992027 acc_eval: 0.9684779898 eprecR_eval: 1.0157468361 time: 14.3406s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0060 nll_train: 0.5144945534 kl_train: -9.3258225830 mse_train: 0.0000514495 acc_train: 0.9854958092 eprecR_train: 1.1125456255 acc_eval: 0.9916096831 eprecR_eval: 1.3197586727 time: 14.2309s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0061 nll_train: 0.0313665360 kl_train: -9.3306191527 mse_train: 0.0000031367 acc_train: 0.9904048667 eprecR_train: 1.2886930076 acc_eval: 0.9915424748 eprecR_eval: 1.3622463164 time: 14.1940s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0062 nll_train: 0.0205231429 kl_train: -9.3308001389 mse_train: 0.0000020523 acc_train: 0.9902393046 eprecR_train: 1.2498183404 acc_eval: 0.9915768495 eprecR_eval: 1.3820335637 time: 14.2020s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0063 nll_train: 0.0267518944 kl_train: -9.3308698689 mse_train: 0.0000026752 acc_train: 0.9900423689 eprecR_train: 1.2674616695 acc_eval: 0.9915592186 eprecR_eval: 1.4411529223 time: 14.1771s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0064 nll_train: 0.0307789950 kl_train: -9.3308772746 mse_train: 0.0000030779 acc_train: 0.9901391766 eprecR_train: 1.2252327942 acc_eval: 0.9916119592 eprecR_eval: 1.2398157988 time: 14.3416s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0065 nll_train: 0.0140780195 kl_train: -9.3309939055 mse_train: 0.0000014078 acc_train: 0.9911464793 eprecR_train: 1.3119533528 acc_eval: 0.9916477330 eprecR_eval: 1.1188811189 time: 14.2339s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0066 nll_train: 0.0154443302 kl_train: -9.3310506373 mse_train: 0.0000015444 acc_train: 0.9912207136 eprecR_train: 1.4077509109 acc_eval: 0.9917001035 eprecR_eval: 1.1111111111 time: 14.2399s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0067 nll_train: 0.0172164000 kl_train: -9.3311084229 mse_train: 0.0000017216 acc_train: 0.9912343905 eprecR_train: 1.2970168612 acc_eval: 0.9917417120 eprecR_eval: 0.8789722786 time: 14.2140s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0068 nll_train: 0.0301951205 kl_train: -9.3311227869 mse_train: 0.0000030195 acc_train: 0.9912456240 eprecR_train: 1.3903251752 acc_eval: 0.9917363234 eprecR_eval: 0.8771929825 time: 14.2034s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0069 nll_train: 0.0374115807 kl_train: -9.3310913451 mse_train: 0.0000037412 acc_train: 0.9912927985 eprecR_train: 1.4970444616 acc_eval: 0.9917253789 eprecR_eval: 0.7905138340 time: 14.2489s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0070 nll_train: 0.0565043537 kl_train: -9.3312544469 mse_train: 0.0000056504 acc_train: 0.9914324212 eprecR_train: 1.2758259545 acc_eval: 0.9917775416 eprecR_eval: 0.8354218881 time: 14.1920s ----------------------------------------------- -----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0071 nll_train: 0.2273196441 kl_train: -9.3305157791 mse_train: 0.0000227320 acc_train: 0.9914756265 eprecR_train: 1.3475888184 acc_eval: 0.9917244461 eprecR_eval: 1.0276172126 time: 14.1556s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0072 nll_train: 0.0595993390 kl_train: -9.3311777645 mse_train: 0.0000059599 acc_train: 0.9915495870 eprecR_train: 1.0346756152 acc_eval: 0.9917925060 eprecR_eval: 0.8130081301 time: 14.2519s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0073 nll_train: 0.0270011268 kl_train: -9.3314184436 mse_train: 0.0000027001 acc_train: 0.9915714355 eprecR_train: 1.0664229129 acc_eval: 0.9917723810 eprecR_eval: 0.6289308176 time: 14.2998s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0074 nll_train: 0.1930845496 kl_train: -9.3312682693 mse_train: 0.0000193085 acc_train: 0.9915339331 eprecR_train: 1.1725955204 acc_eval: 0.9917821951 eprecR_eval: 0.7049345418 time: 15.2333s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0075 nll_train: 0.0294221254 kl_train: -9.3315102966 mse_train: 0.0000029422 acc_train: 0.9915497644 eprecR_train: 1.1717171717 acc_eval: 0.9917825703 eprecR_eval: 0.6289308176 time: 14.4164s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0076 nll_train: 0.1183597368 kl_train: -9.3315022374 mse_train: 0.0000118360 acc_train: 0.9915111113 eprecR_train: 1.3104283669 acc_eval: 0.9917666578 eprecR_eval: 0.8130081301 time: 14.2688s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0077 nll_train: 0.0293355227 kl_train: -9.3316191332 mse_train: 0.0000029336 acc_train: 0.9915960316 eprecR_train: 1.2395459976 acc_eval: 0.9917922171 eprecR_eval: 0.7380073801 time: 14.1870s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 5.0000e-04.\n",
      "Epoch: 0078 nll_train: 0.1492335317 kl_train: -9.3304852085 mse_train: 0.0000149234 acc_train: 0.9914829718 eprecR_train: 1.5243164771 acc_eval: 0.9917928051 eprecR_eval: 0.3003003003 time: 14.3157s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0079 nll_train: 0.0143041607 kl_train: -9.3316667463 mse_train: 0.0000014304 acc_train: 0.9915914084 eprecR_train: 1.3950073421 acc_eval: 0.9917733391 eprecR_eval: 0.9554140127 time: 14.1811s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0080 nll_train: 0.0086391104 kl_train: -9.3319419048 mse_train: 0.0000008639 acc_train: 0.9916241660 eprecR_train: 1.2795489048 acc_eval: 0.9917477140 eprecR_eval: 0.7374631268 time: 14.2868s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0081 nll_train: 0.0072643295 kl_train: -9.3319784388 mse_train: 0.0000007264 acc_train: 0.9916730286 eprecR_train: 0.9793253536 acc_eval: 0.9917805172 eprecR_eval: 0.8403361345 time: 14.2157s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0082 nll_train: 0.0070734092 kl_train: -9.3319929912 mse_train: 0.0000007073 acc_train: 0.9916908673 eprecR_train: 1.0344827586 acc_eval: 0.9917794375 eprecR_eval: 0.8130081301 time: 14.3426s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0083 nll_train: 0.0070593761 kl_train: -9.3320032873 mse_train: 0.0000007059 acc_train: 0.9916836588 eprecR_train: 0.9404388715 acc_eval: 0.9917625264 eprecR_eval: 0.8771929825 time: 14.3097s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0084 nll_train: 0.0071251972 kl_train: -9.3320236559 mse_train: 0.0000007125 acc_train: 0.9916880387 eprecR_train: 0.9116131589 acc_eval: 0.9917676464 eprecR_eval: 0.8090614887 time: 14.2110s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0085 nll_train: 0.0067339346 kl_train: -9.3320336577 mse_train: 0.0000006734 acc_train: 0.9916876281 eprecR_train: 0.9746588694 acc_eval: 0.9917788038 eprecR_eval: 0.8818342152 time: 14.2549s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0086 nll_train: 0.0066517912 kl_train: -9.3320360714 mse_train: 0.0000006652 acc_train: 0.9916855750 eprecR_train: 0.9701202949 acc_eval: 0.9917730198 eprecR_eval: 0.7832898172 time: 14.2230s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0087 nll_train: 0.0061029893 kl_train: -9.3320539027 mse_train: 0.0000006103 acc_train: 0.9916926466 eprecR_train: 0.9009009009 acc_eval: 0.9917842330 eprecR_eval: 0.8522727273 time: 14.2858s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0088 nll_train: 0.0068140734 kl_train: -9.3320663476 mse_train: 0.0000006814 acc_train: 0.9916977108 eprecR_train: 0.9488448845 acc_eval: 0.9917876547 eprecR_eval: 0.8746355685 time: 14.2160s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0089 nll_train: 0.0061829089 kl_train: -9.3320708628 mse_train: 0.0000006183 acc_train: 0.9917054364 eprecR_train: 0.9294465568 acc_eval: 0.9917969264 eprecR_eval: 0.7751937984 time: 14.2389s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0090 nll_train: 0.0082498595 kl_train: -9.3320796931 mse_train: 0.0000008250 acc_train: 0.9916946541 eprecR_train: 0.9615384615 acc_eval: 0.9917871072 eprecR_eval: 0.8823529412 time: 14.1913s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0091 nll_train: 0.0063515412 kl_train: -9.3320776445 mse_train: 0.0000006352 acc_train: 0.9916980302 eprecR_train: 0.9758001561 acc_eval: 0.9917873962 eprecR_eval: 0.8902077151 time: 14.3177s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0092 nll_train: 0.0062787144 kl_train: -9.3320955347 mse_train: 0.0000006279 acc_train: 0.9916741388 eprecR_train: 1.0323281717 acc_eval: 0.9917925567 eprecR_eval: 0.9832841691 time: 14.2997s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0093 nll_train: 0.0130805516 kl_train: -9.3320939158 mse_train: 0.0000013081 acc_train: 0.9916538769 eprecR_train: 1.1072664360 acc_eval: 0.9917877054 eprecR_eval: 0.8695652174 time: 14.2658s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0094 nll_train: 0.0156859099 kl_train: -9.3320673719 mse_train: 0.0000015686 acc_train: 0.9916334427 eprecR_train: 1.1184341921 acc_eval: 0.9917897534 eprecR_eval: 0.9174311927 time: 14.2080s ----------------------------------------------- -----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0095 nll_train: 0.0062056763 kl_train: -9.3321027815 mse_train: 0.0000006206 acc_train: 0.9916600868 eprecR_train: 1.1334721258 acc_eval: 0.9918004039 eprecR_eval: 0.9592326139 time: 14.1920s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0096 nll_train: 0.0066339137 kl_train: -9.3321255166 mse_train: 0.0000006634 acc_train: 0.9916602236 eprecR_train: 1.1797362942 acc_eval: 0.9917996739 eprecR_eval: 1.0489510490 time: 14.2955s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0097 nll_train: 0.0057716651 kl_train: -9.3321205481 mse_train: 0.0000005772 acc_train: 0.9916654754 eprecR_train: 0.9644789461 acc_eval: 0.9918060359 eprecR_eval: 1.1320754717 time: 14.2858s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0098 nll_train: 0.0076032480 kl_train: -9.3321308324 mse_train: 0.0000007603 acc_train: 0.9916635136 eprecR_train: 0.9715475364 acc_eval: 0.9918086465 eprecR_eval: 1.1157601116 time: 14.2250s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0099 nll_train: 0.0231210325 kl_train: -9.3321024165 mse_train: 0.0000023121 acc_train: 0.9916657491 eprecR_train: 1.0693970421 acc_eval: 0.9918080991 eprecR_eval: 1.0973936900 time: 14.2948s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0100 nll_train: 0.0193885976 kl_train: -9.3321134367 mse_train: 0.0000019389 acc_train: 0.9916411581 eprecR_train: 1.2078601046 acc_eval: 0.9918041298 eprecR_eval: 1.1204481793 time: 14.2070s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0101 nll_train: 0.0076890814 kl_train: -9.3321427534 mse_train: 0.0000007689 acc_train: 0.9916682584 eprecR_train: 0.9926131117 acc_eval: 0.9918095590 eprecR_eval: 1.2012012012 time: 14.3696s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0102 nll_train: 0.0110748069 kl_train: -9.3321579062 mse_train: 0.0000011075 acc_train: 0.9916684409 eprecR_train: 1.0060362173 acc_eval: 0.9918097415 eprecR_eval: 1.1326860841 time: 14.2086s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0103 nll_train: 0.0304529727 kl_train: -9.3321734122 mse_train: 0.0000030453 acc_train: 0.9916789292 eprecR_train: 0.8703220191 acc_eval: 0.9918005712 eprecR_eval: 0.9845288326 time: 14.1930s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0104 nll_train: 0.0290345779 kl_train: -9.3321095808 mse_train: 0.0000029035 acc_train: 0.9916931231 eprecR_train: 1.0641357492 acc_eval: 0.9918122609 eprecR_eval: 1.3333333333 time: 14.2060s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0105 nll_train: 0.0438424194 kl_train: -9.3320294133 mse_train: 0.0000043842 acc_train: 0.9916980048 eprecR_train: 1.1328235627 acc_eval: 0.9918155458 eprecR_eval: 1.2477718360 time: 14.5970s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0106 nll_train: 0.0252616836 kl_train: -9.3321304086 mse_train: 0.0000025262 acc_train: 0.9916867815 eprecR_train: 1.2345679012 acc_eval: 0.9918072322 eprecR_eval: 1.0752688172 time: 14.3177s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0107 nll_train: 0.0188410975 kl_train: -9.3321573234 mse_train: 0.0000018841 acc_train: 0.9916997385 eprecR_train: 1.1071214841 acc_eval: 0.9918082359 eprecR_eval: 1.1006289308 time: 14.2638s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0108 nll_train: 0.0101841957 kl_train: -9.3322006037 mse_train: 0.0000010184 acc_train: 0.9916930319 eprecR_train: 1.2503125781 acc_eval: 0.9918163670 eprecR_eval: 1.1111111111 time: 14.2589s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0109 nll_train: 0.0500098743 kl_train: -9.3321386855 mse_train: 0.0000050010 acc_train: 0.9916946287 eprecR_train: 1.2461059190 acc_eval: 0.9918186026 eprecR_eval: 1.4227642276 time: 14.2179s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0110 nll_train: 0.0109557876 kl_train: -9.3322168574 mse_train: 0.0000010956 acc_train: 0.9916976399 eprecR_train: 1.1568469196 acc_eval: 0.9918100609 eprecR_eval: 1.0000000000 time: 14.2599s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0111 nll_train: 0.0512575191 kl_train: -9.3320791044 mse_train: 0.0000051258 acc_train: 0.9917017510 eprecR_train: 1.2527634488 acc_eval: 0.9918186127 eprecR_eval: 1.3333333333 time: 14.1739s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0112 nll_train: 0.0304957017 kl_train: -9.3321238212 mse_train: 0.0000030496 acc_train: 0.9917337026 eprecR_train: 1.5017956252 acc_eval: 0.9918281378 eprecR_eval: 1.2437810945 time: 14.1645s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0113 nll_train: 0.0100744977 kl_train: -9.3322054192 mse_train: 0.0000010074 acc_train: 0.9917393903 eprecR_train: 1.3902360168 acc_eval: 0.9918270885 eprecR_eval: 1.0416666667 time: 14.1667s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0114 nll_train: 0.0762556073 kl_train: -9.3319463200 mse_train: 0.0000076256 acc_train: 0.9917424166 eprecR_train: 1.4191419142 acc_eval: 0.9918288729 eprecR_eval: 1.2722646310 time: 14.2287s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0115 nll_train: 0.0134255283 kl_train: -9.3322003506 mse_train: 0.0000013426 acc_train: 0.9917590235 eprecR_train: 1.4063093881 acc_eval: 0.9918281378 eprecR_eval: 1.0840108401 time: 14.2511s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0116 nll_train: 0.0371437551 kl_train: -9.3322369611 mse_train: 0.0000037144 acc_train: 0.9917741705 eprecR_train: 1.1406844106 acc_eval: 0.9918292835 eprecR_eval: 1.3550135501 time: 14.2018s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0117 nll_train: 0.0108944566 kl_train: -9.3322505245 mse_train: 0.0000010894 acc_train: 0.9917714331 eprecR_train: 1.0791366906 acc_eval: 0.9918288729 eprecR_eval: 1.2626262626 time: 14.1389s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0118 nll_train: 0.0085162815 kl_train: -9.3322954060 mse_train: 0.0000008516 acc_train: 0.9917740792 eprecR_train: 1.3675213675 acc_eval: 0.9918292734 eprecR_eval: 1.3227513228 time: 14.2152s ----------------------------------------------- -----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0119 nll_train: 0.0157989095 kl_train: -9.3322758321 mse_train: 0.0000015799 acc_train: 0.9917794628 eprecR_train: 1.5277777778 acc_eval: 0.9918291466 eprecR_eval: 1.8372703412 time: 14.2209s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0120 nll_train: 0.0800492359 kl_train: -9.3320509063 mse_train: 0.0000080049 acc_train: 0.9917720718 eprecR_train: 1.5784586815 acc_eval: 0.9918304241 eprecR_eval: 1.6025641026 time: 14.2229s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0121 nll_train: 0.0329340921 kl_train: -9.3321843206 mse_train: 0.0000032934 acc_train: 0.9917951116 eprecR_train: 1.1019283747 acc_eval: 0.9918313822 eprecR_eval: 1.5686274510 time: 14.1414s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0122 nll_train: 0.0199878806 kl_train: -9.3322946702 mse_train: 0.0000019988 acc_train: 0.9918032782 eprecR_train: 0.7002801120 acc_eval: 0.9918308347 eprecR_eval: 1.6835016835 time: 14.2258s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0123 nll_train: 0.0110590009 kl_train: -9.3323294498 mse_train: 0.0000011059 acc_train: 0.9918104867 eprecR_train: 0.8912655971 acc_eval: 0.9918317928 eprecR_eval: 1.7094017094 time: 14.1717s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0124 nll_train: 0.0054873753 kl_train: -9.3323504366 mse_train: 0.0000005487 acc_train: 0.9918088442 eprecR_train: 0.8417508418 acc_eval: 0.9918304241 eprecR_eval: 1.8691588785 time: 14.2763s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0125 nll_train: 0.0069073328 kl_train: -9.3323689390 mse_train: 0.0000006907 acc_train: 0.9918077949 eprecR_train: 0.8012820513 acc_eval: 0.9918305153 eprecR_eval: 2.2222222222 time: 14.1723s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0125\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0126 nll_train: 0.0156083171 kl_train: -9.3323253055 mse_train: 0.0000015608 acc_train: 0.9918103498 eprecR_train: 0.8503401361 acc_eval: 0.9918315647 eprecR_eval: 2.3809523810 time: 14.1866s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0126\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0127 nll_train: 0.0570361058 kl_train: -9.3322789228 mse_train: 0.0000057036 acc_train: 0.9918150490 eprecR_train: 0.5952380952 acc_eval: 0.9918318384 eprecR_eval: 2.6666666667 time: 14.2278s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0127\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0128 nll_train: 0.0750696567 kl_train: -9.3320724523 mse_train: 0.0000075070 acc_train: 0.9918171021 eprecR_train: 0.8281573499 acc_eval: 0.9918331615 eprecR_eval: 2.8368794326 time: 14.1504s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0128\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0129 nll_train: 0.0145407391 kl_train: -9.3323667432 mse_train: 0.0000014541 acc_train: 0.9918150946 eprecR_train: 0.7619047619 acc_eval: 0.9918323859 eprecR_eval: 2.6041666667 time: 14.2359s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0130 nll_train: 0.0038818807 kl_train: -9.3324301567 mse_train: 0.0000003882 acc_train: 0.9918124485 eprecR_train: 1.0152284264 acc_eval: 0.9918318384 eprecR_eval: 2.6666666667 time: 14.1741s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0131 nll_train: 0.0142850395 kl_train: -9.3324191835 mse_train: 0.0000014285 acc_train: 0.9918089811 eprecR_train: 1.0101010101 acc_eval: 0.9918303328 eprecR_eval: 1.7361111111 time: 14.2222s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0132 nll_train: 0.0080775625 kl_train: -9.3324079160 mse_train: 0.0000008078 acc_train: 0.9918125397 eprecR_train: 0.9174311927 acc_eval: 0.9918309716 eprecR_eval: 2.2222222222 time: 14.1251s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0133 nll_train: 0.0274271389 kl_train: -9.3323011281 mse_train: 0.0000027427 acc_train: 0.9918064718 eprecR_train: 0.7788161994 acc_eval: 0.9918322034 eprecR_eval: 1.9323671498 time: 14.2828s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0134 nll_train: 0.0099670684 kl_train: -9.3324097292 mse_train: 0.0000009967 acc_train: 0.9918193376 eprecR_train: 0.6666666667 acc_eval: 0.9918316103 eprecR_eval: 2.5641025641 time: 14.1944s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0135 nll_train: 0.0749262344 kl_train: -9.3319735174 mse_train: 0.0000074926 acc_train: 0.9918058787 eprecR_train: 0.8368200837 acc_eval: 0.9918320209 eprecR_eval: 2.3148148148 time: 14.2135s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0136 nll_train: 0.0130010688 kl_train: -9.3324157691 mse_train: 0.0000013001 acc_train: 0.9918212994 eprecR_train: 1.1904761905 acc_eval: 0.9918327053 eprecR_eval: 3.2051282051 time: 14.1897s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0136\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0137 nll_train: 0.0300600567 kl_train: -9.3323801712 mse_train: 0.0000030060 acc_train: 0.9918236718 eprecR_train: 2.1367521368 acc_eval: 0.9918340740 eprecR_eval: 4.5977011494 time: 14.1840s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0137\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0138 nll_train: 0.0173568463 kl_train: -9.3324545225 mse_train: 0.0000017357 acc_train: 0.9918264549 eprecR_train: 0.3333333333 acc_eval: 0.9918334808 eprecR_eval: 3.3333333333 time: 14.3022s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0139 nll_train: 0.0166208631 kl_train: -9.3324402585 mse_train: 0.0000016621 acc_train: 0.9918285535 eprecR_train: 0.0000000000 acc_eval: 0.9918337546 eprecR_eval: 3.9215686275 time: 14.2301s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0140 nll_train: 0.0043633952 kl_train: -9.3325027831 mse_train: 0.0000004363 acc_train: 0.9918316103 eprecR_train: 0.0000000000 acc_eval: 0.9918346214 eprecR_eval: 3.9215686275 time: 14.1650s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0141 nll_train: 0.0042929957 kl_train: -9.3325208440 mse_train: 0.0000004293 acc_train: 0.9918297397 eprecR_train: 0.4219409283 acc_eval: 0.9918345302 eprecR_eval: 5.2631578947 time: 14.1930s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0142 nll_train: 0.0043536581 kl_train: -9.3325259009 mse_train: 0.0000004354 acc_train: 0.9918288729 eprecR_train: 0.0000000000 acc_eval: 0.9918346214 eprecR_eval: 3.9215686275 time: 14.1607s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0143 nll_train: 0.0359930505 kl_train: -9.3324675442 mse_train: 0.0000035993 acc_train: 0.9918308803 eprecR_train: 0.0000000000 acc_eval: 0.9918340283 eprecR_eval: 4.5977011494 time: 14.2985s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0144 nll_train: 0.2048493482 kl_train: -9.3311225102 mse_train: 0.0000204849 acc_train: 0.9918219381 eprecR_train: 1.5594541910 acc_eval: 0.9918344389 eprecR_eval: 4.7619047619 time: 14.1919s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0145 nll_train: 0.0038780316 kl_train: -9.3325479531 mse_train: 0.0000003878 acc_train: 0.9918316559 eprecR_train: 0.6060606061 acc_eval: 0.9918345758 eprecR_eval: 5.5555555556 time: 14.1867s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0145\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0146 nll_train: 0.0034930443 kl_train: -9.3325671090 mse_train: 0.0000003493 acc_train: 0.9918331159 eprecR_train: 0.0000000000 acc_eval: 0.9918348952 eprecR_eval: 3.0303030303 time: 14.1668s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0147 nll_train: 0.0039532443 kl_train: -9.3325736846 mse_train: 0.0000003953 acc_train: 0.9918329334 eprecR_train: 0.0000000000 acc_eval: 0.9918348952 eprecR_eval: 3.0303030303 time: 14.2700s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0148 nll_train: 0.0035826111 kl_train: -9.3325729723 mse_train: 0.0000003583 acc_train: 0.9918332527 eprecR_train: 0.0000000000 acc_eval: 0.9918348952 eprecR_eval: 3.0303030303 time: 14.2008s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0149 nll_train: 0.0062079781 kl_train: -9.3325482945 mse_train: 0.0000006208 acc_train: 0.9918334352 eprecR_train: 0.0000000000 acc_eval: 0.9918348952 eprecR_eval: 3.0303030303 time: 14.1712s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0150 nll_train: 0.0050610533 kl_train: -9.3325528274 mse_train: 0.0000005061 acc_train: 0.9918311084 eprecR_train: 0.0000000000 acc_eval: 0.9918349864 eprecR_eval: 3.7037037037 time: 14.1857s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0151 nll_train: 0.0056280892 kl_train: -9.3325755743 mse_train: 0.0000005628 acc_train: 0.9918338002 eprecR_train: 0.0000000000 acc_eval: 0.9918349864 eprecR_eval: 3.7037037037 time: 14.2018s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0152 nll_train: 0.0114395468 kl_train: -9.3324993746 mse_train: 0.0000011440 acc_train: 0.9918338002 eprecR_train: 0.0000000000 acc_eval: 0.9918349864 eprecR_eval: 3.7037037037 time: 14.2853s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0153 nll_train: 0.0033188812 kl_train: -9.3325662495 mse_train: 0.0000003319 acc_train: 0.9918319753 eprecR_train: 0.0000000000 acc_eval: 0.9918350777 eprecR_eval: 4.7619047619 time: 14.1874s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0154 nll_train: 0.0030476841 kl_train: -9.3326097535 mse_train: 0.0000003048 acc_train: 0.9918335265 eprecR_train: 0.0000000000 acc_eval: 0.9918350777 eprecR_eval: 4.7619047619 time: 14.1635s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0155 nll_train: 0.0088832604 kl_train: -9.3325838689 mse_train: 0.0000008883 acc_train: 0.9918336177 eprecR_train: 0.0000000000 acc_eval: 0.9918353514 eprecR_eval: 0.0000000000 time: 14.1587s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0156 nll_train: 0.1791377587 kl_train: -9.3284767233 mse_train: 0.0000179138 acc_train: 0.9914646617 eprecR_train: 0.5453431373 acc_eval: 0.9918353970 eprecR_eval: 0.0000000000 time: 14.2430s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0157 nll_train: 0.0129873115 kl_train: -9.3319077080 mse_train: 0.0000012987 acc_train: 0.9918286904 eprecR_train: 1.1185682327 acc_eval: 0.9918353514 eprecR_eval: 0.0000000000 time: 14.2454s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 2.0000e-04.\n",
      "Epoch: 0158 nll_train: 0.0187477485 kl_train: -9.3326060919 mse_train: 0.0000018748 acc_train: 0.9918348952 eprecR_train: 0.0000000000 acc_eval: 0.9918353058 eprecR_eval: 16.6666666667 time: 14.1949s ----------------------------------------------- -----------------------------------------------\n",
      "Best model so far, saving...\n",
      "Epoch: 0158\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0159 nll_train: 0.0058517651 kl_train: -9.3326371982 mse_train: 0.0000005852 acc_train: 0.9918347583 eprecR_train: 0.0000000000 acc_eval: 0.9918353514 eprecR_eval: 0.0000000000 time: 14.1594s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0160 nll_train: 0.0028039104 kl_train: -9.3327822097 mse_train: 0.0000002804 acc_train: 0.9918350777 eprecR_train: 0.0000000000 acc_eval: 0.9918353970 eprecR_eval: 0.0000000000 time: 14.2137s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0161 nll_train: 0.0023702778 kl_train: -9.3327992051 mse_train: 0.0000002370 acc_train: 0.9918351233 eprecR_train: 0.0000000000 acc_eval: 0.9918353970 eprecR_eval: 0.0000000000 time: 14.2550s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0162 nll_train: 0.0023791709 kl_train: -9.3328039205 mse_train: 0.0000002379 acc_train: 0.9918351233 eprecR_train: 0.0000000000 acc_eval: 0.9918353970 eprecR_eval: 0.0000000000 time: 14.1624s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0163 nll_train: 0.0025238557 kl_train: -9.3328017894 mse_train: 0.0000002524 acc_train: 0.9918350777 eprecR_train: 0.0000000000 acc_eval: 0.9918353970 eprecR_eval: 0.0000000000 time: 14.1658s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0164 nll_train: 0.0026829700 kl_train: -9.3328040323 mse_train: 0.0000002683 acc_train: 0.9918349864 eprecR_train: 0.0000000000 acc_eval: 0.9918353970 eprecR_eval: 0.0000000000 time: 14.1953s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0165 nll_train: 0.0023465382 kl_train: -9.3328049507 mse_train: 0.0000002347 acc_train: 0.9918350320 eprecR_train: 0.0000000000 acc_eval: 0.9918353970 eprecR_eval: 0.0000000000 time: 14.1880s ----------------------------------------------- -----------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0166 nll_train: 0.0021644690 kl_train: -9.3328060397 mse_train: 0.0000002164 acc_train: 0.9918350320 eprecR_train: 0.0000000000 acc_eval: 0.9918353514 eprecR_eval: 0.0000000000 time: 14.2567s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0167 nll_train: 0.0021750174 kl_train: -9.3328107963 mse_train: 0.0000002175 acc_train: 0.9918348495 eprecR_train: 0.0000000000 acc_eval: 0.9918353514 eprecR_eval: 0.0000000000 time: 14.1834s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0168 nll_train: 0.0022362783 kl_train: -9.3328095895 mse_train: 0.0000002236 acc_train: 0.9918348495 eprecR_train: 0.0000000000 acc_eval: 0.9918353058 eprecR_eval: 16.6666666667 time: 14.1261s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0169 nll_train: 0.0021693268 kl_train: -9.3328105314 mse_train: 0.0000002169 acc_train: 0.9918348952 eprecR_train: 0.0000000000 acc_eval: 0.9918353058 eprecR_eval: 16.6666666667 time: 14.2033s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0170 nll_train: 0.0022968436 kl_train: -9.3328114321 mse_train: 0.0000002297 acc_train: 0.9918348039 eprecR_train: 0.0000000000 acc_eval: 0.9918353058 eprecR_eval: 16.6666666667 time: 14.2175s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0171 nll_train: 0.0022710036 kl_train: -9.3328150172 mse_train: 0.0000002271 acc_train: 0.9918349408 eprecR_train: 0.0000000000 acc_eval: 0.9918353058 eprecR_eval: 16.6666666667 time: 14.2098s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0172 nll_train: 0.0022480977 kl_train: -9.3328127920 mse_train: 0.0000002248 acc_train: 0.9918348039 eprecR_train: 0.0000000000 acc_eval: 0.9918353058 eprecR_eval: 16.6666666667 time: 14.1612s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0173 nll_train: 0.0020844087 kl_train: -9.3328138104 mse_train: 0.0000002084 acc_train: 0.9918349408 eprecR_train: 0.0000000000 acc_eval: 0.9918353058 eprecR_eval: 16.6666666667 time: 14.2332s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0174 nll_train: 0.0021590847 kl_train: -9.3328162240 mse_train: 0.0000002159 acc_train: 0.9918350777 eprecR_train: 0.0000000000 acc_eval: 0.9918353058 eprecR_eval: 16.6666666667 time: 14.1831s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0175 nll_train: 0.0027571575 kl_train: -9.3328149996 mse_train: 0.0000002757 acc_train: 0.9918349408 eprecR_train: 0.0000000000 acc_eval: 0.9918353058 eprecR_eval: 16.6666666667 time: 14.2792s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0176 nll_train: 0.0020117809 kl_train: -9.3328168127 mse_train: 0.0000002012 acc_train: 0.9918348952 eprecR_train: 0.0000000000 acc_eval: 0.9918353058 eprecR_eval: 16.6666666667 time: 14.1657s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0177 nll_train: 0.0027212034 kl_train: -9.3328139988 mse_train: 0.0000002721 acc_train: 0.9918348039 eprecR_train: 0.0000000000 acc_eval: 0.9918353058 eprecR_eval: 16.6666666667 time: 14.2289s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0178 nll_train: 0.0033468707 kl_train: -9.3328045445 mse_train: 0.0000003347 acc_train: 0.9918346671 eprecR_train: 0.0000000000 acc_eval: 0.9918353058 eprecR_eval: 16.6666666667 time: 14.1747s ----------------------------------------------- -----------------------------------------------\n",
      "Adjusting learning rate of group 0 to 8.0000e-05.\n",
      "Epoch: 0179 nll_train: 0.0026171961 kl_train: -9.3328131275 mse_train: 0.0000002617 acc_train: 0.9918347127 eprecR_train: 0.0000000000 acc_eval: 0.9918353514 eprecR_eval: 0.0000000000 time: 14.1537s ----------------------------------------------- -----------------------------------------------\n",
      "Optimization Finished!\n",
      "Best Epoch: 0158\n",
      "16.666666666666668\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "t_total = time.time()\n",
    "best_eprec = 0\n",
    "best_epoch = 0\n",
    "for epoch in range(args.epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    eprec = train(epoch, best_eprec) \n",
    "    if eprec > best_eprec:\n",
    "        best_eprec = eprec\n",
    "        best_epoch = epoch\n",
    "print(\"Optimization Finished!\")\n",
    "print(\"Best Epoch: {:04d}\".format(best_epoch))\n",
    "print(best_eprec)\n",
    "if args.save_folder:\n",
    "    print(\"Best Epoch: {:04d}\".format(best_epoch), file=log)\n",
    "    log.flush()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
